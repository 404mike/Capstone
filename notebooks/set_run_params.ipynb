{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is an interface to conveniently create the run paramters file for either script (Dimensional Reduction or Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/r0b00sj/Documents/Capstone/Capstone/py_scripts\n"
     ]
    }
   ],
   "source": [
    "cd ../py_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from utils_streamers import DirFileMgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensional Reduction  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter unique ID string HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr_id_str = 'gpu_mod_run_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-490142876ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdr_fps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirFileMgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdr_id_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdr_fps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_all_dr_fps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_setup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Capstone/Capstone/py_scripts/utils_streamers.py\u001b[0m in \u001b[0;36mcreate_all_dr_fps\u001b[0;34m(self, new_setup)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_setup\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_fp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source_dir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_fp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corp_lst'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_fp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dictionary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Capstone/Capstone/py_scripts/utils_streamers.py\u001b[0m in \u001b[0;36madd_fp\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyLDAvis html fp is assigned as \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'source_dir'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mwhich_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Which data set will be used? Enter either '5000' or 'full': \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;31m#^ this is super useful for development but should be removed for final reproducibility code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m#relative filepaths - various options for various corp sizes for dev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dr_fps = DirFileMgr(dr_id_str)\n",
    "dr_fps.create_all_dr_fps(new_setup='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set run parameters for the dimensional reduction stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Minimum number of documents that a token must appear in (otherwise it is filtered out)\n",
    "min_freq = 5  #Default 5; set to None to skip frequency filtering\n",
    "\n",
    "#Maximum percentage of the corpus in which a token can appear (otherwise it is filtered out)\n",
    "max_freq = 0.5  #Default 0.5\n",
    "\n",
    "#Number of words to keep in dictionary\n",
    "keep_n = 2000000  #Gensim default = 100000; I changed it here since our docs are so large (books)\n",
    "\n",
    "#Dataset used\n",
    "dataset = dr_fps.source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr_d = { 'min_freq' : min_freq, 'max_freq' : max_freq, 'keep_n' : keep_n, \\\n",
    "       'dataset' : dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dump(dr_d, open(dr_fps.dr_run_params, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter unique ID string HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod_id_str = 'gpu_mod_run_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus lst fp is assigned as  ../../outputs-git_ignored/gpu_mod_run_1/gpu_mod_run_1_lst.txt\n",
      "dictionary fp is assigned as  ../../outputs-git_ignored/gpu_mod_run_1/gpu_mod_run_1.dict\n",
      "counts dictionary fp is assigned as  ../../outputs-git_ignored/gpu_mod_run_1/gpu_mod_run_1_json.txt\n",
      "model fp is assigned as  ../../outputs-git_ignored/gpu_mod_run_1/gpu_mod_run_1.model\n",
      "modeling run parameters fp is assigned as  ../../outputs-git_ignored/gpu_mod_run_1/gpu_mod_run_1_mod_run_params.txt\n"
     ]
    }
   ],
   "source": [
    "mod_fps = DirFileMgr(mod_id_str)\n",
    "mod_fps.create_all_modeling_fps(mod_id_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set run parameters for the modeling stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, gensim defaults:\n",
    "corpus=None, num_topics=100, id2word=None, workers=None, chunksize=2000, passes=1, batch=False, alpha='symmetric', eta=None, decay=0.5, offset=1.0, eval_every=10, iterations=50, gamma_threshold=0.001, random_state=None, minimum_probability=0.01, minimum_phi_value=0.01, per_word_topics=False, dtype=type 'numpy.float32'\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamulticore.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 * 8 * terms * topics\n",
    "\n",
    "#Number of topics for LDA to train on\n",
    "num_topics = 50  #Project default: 50 (for entire corpus)\n",
    "\n",
    "#Number of cores on the machine running the modeling script\n",
    "cores = 2 #Common values: \n",
    "            #recent macbook=2, \n",
    "            #recent macbook pro= 4 or 2\n",
    "            #recent macbook air=2\n",
    "            #t2.xlarge ec2=4\n",
    "            #Spec too few cores and run is computationally sub-optimized\n",
    "            #Spec too many and run may fail\n",
    "#Workers will be equal to number of cores - 1\n",
    "\n",
    "#Number of docs to process at a time\n",
    "chunksize = 2000  #Default 2000\n",
    "\n",
    "#Number of training passes for LDA algorithm\n",
    "passes = 10  #Default 1\n",
    "#10 might be high, esp for large corpus - I see 1-5 type values\n",
    "\n",
    "#If batch is not set, perform online training by updating the model once \n",
    "#every workers * chunksize documents (online training). \n",
    "#Otherwise, run batch LDA, updating model only once at the end of each full corpus pass.\n",
    "batch = False\n",
    "\n",
    "#alpha and eta are hyperparameters that affect sparsity of the document-topic (theta) \n",
    "#and topic-word (lambda) distributions. Both default to a symmetric \n",
    "#1.0/num_topics prior.\n",
    "\n",
    "#alpha can be set to an explicit array = prior of your choice. It also \n",
    "#support special values of ‘asymmetric’ and ‘auto’: the former uses a \n",
    "#fixed normalized asymmetric 1.0/topicno prior, the latter learns an \n",
    "#asymmetric prior directly from your data.\n",
    "alpha = 'symmetric'\n",
    "\n",
    "#eta can be a scalar for a symmetric prior over topic/word distributions, \n",
    "#or a matrix of shape num_topics x num_words, which can be used to impose \n",
    "#asymmetric priors over the word distribution on a per-topic basis. This \n",
    "#may be useful if you want to seed certain topics with particular words by \n",
    "#boosting the priors for those words.\n",
    "eta = None\n",
    "\n",
    "#decay and offset parameters are the same as Kappa and Tau_0 in Hoffman \n",
    "#et al, respectively.\n",
    "#http://papers.nips.cc/paper/3902-online-learning-for-latent-dirichlet-allocation.pdf\n",
    "decay = 0.5\n",
    "offset = 1.0\n",
    "\n",
    "#Calculate and log perplexity estimate from the latest mini-batch once \n",
    "#every eval_every documents. Set to None to disable perplexity estimation \n",
    "#(faster), or to 0 to only evaluate perplexity once, at the end of each \n",
    "#corpus pass.\n",
    "eval_every = 10\n",
    "\n",
    "iterations = 50\n",
    "#https://groups.google.com/forum/#!topic/gensim/aGXc0qiVBhU\n",
    "\n",
    "#iterations continue until the difference between two consecutive topic (gamma) \n",
    "#estimates is less than `gamma_threshold`\n",
    "gamma_threshold = 0.001\n",
    "#https://groups.google.com/forum/#!topic/gensim/aGXc0qiVBhU\n",
    "\n",
    "random_state = None\n",
    "\n",
    "#controls filtering the topics returned for a document\n",
    "minimum_probability = 0.01\n",
    "\n",
    "minimum_phi_value = 0.01\n",
    "\n",
    "per_word_topic = False\n",
    "\n",
    "#-----------\n",
    "#How often to do the maximization step as related to chunk size - for single LDA only\n",
    "update_every = 0  #Default 0\n",
    "#See this link for more detail: https://groups.google.com/forum/#!topic/gensim/ojySenxQHi4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keep_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b5e5e5b86f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#rule of thumb for memory reqts is 8 bytes per term per topic:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mkeep_n\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#if this number is higher than your available memory, need to limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#terms and/or topics, or get more memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keep_n' is not defined"
     ]
    }
   ],
   "source": [
    "#rule of thumb for memory reqts is 8 bytes per term per topic:\n",
    "8 * keep_n * num_topics\n",
    "#if this number is higher than your available memory, need to limit  \n",
    "#terms and/or topics, or get more memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod_d = {'num_topics' : num_topics, \\\n",
    "         'cores' : cores, \\\n",
    "         'chunksize' : chunksize, \\\n",
    "         'passes' : passes, \\\n",
    "         'batch' : batch,\\\n",
    "         'alpha' : alpha, \\\n",
    "         'eta' : eta, \\\n",
    "         'decay' : decay, \\\n",
    "         'offset' : offset, \\\n",
    "         'eval_every' : eval_every, \\\n",
    "         'iterations' : iterations, \\\n",
    "         'gamma_threshold' : gamma_threshold, \\\n",
    "         'random_state' : random_state, \\\n",
    "         'minimum_probability' : minimum_probability, \\\n",
    "         'minimum_phi_value' : minimum_phi_value, \\\n",
    "         'per_word_topic' : minimum_phi_value, \\\n",
    "         'update_every' : update_every }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dump(mod_d, open(mod_fps.mod_run_params, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
